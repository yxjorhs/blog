# mysql如何将数据从内存同步到磁盘

mysql的数据是保存在磁盘的，进程想要获取磁盘的数据就得先加载到内存，缓冲池便是这样一个保存磁盘数据的内存空间，然而**数据是怎么从磁盘到缓冲池的?**

当我们对数据执行修改操作，缓冲池的数据相对磁盘发生了变化，数据又是**怎么从内存同步回磁盘的?**

万一数据还**没同步到磁盘进程崩溃了则么办?**



# 缓冲池

缓冲池是保存磁盘数据拷贝的内存空间，服务器初始化的时候便分配好了这个空间的容量(大小可以通过配置修改)

## 缓存页

磁盘是以页作为单位保存数据，缓冲池便相应地以页作为单位缓存磁盘数据，大小也是16k，这些缓存页在缓冲池中以数组的形式保存

## 控制块

为了更好地管理这些缓存页，每一个缓存页都有一个对应的控制块，保存了对应的缓存页的信息(表空间id，页号，指向缓存页地址的指针等)

这些控制块与缓存页一一对应，缓冲池有多少个缓存页就有多少个控制块，缓冲池能缓存多少个缓存页取决于缓冲池的大小除以(缓存页大小 + 控制块大小)



## 链表

缓存页在缓冲池以数据的结构保存，数组结构在元素较多时存在移动开销大、性能低的问题，因此对于需要按照一定顺序排序、且需要经常移动元素的数组，更好的方式是以链表的形式来实现

### free链表

为了更方便地获取缓冲池中的空白缓冲页，缓冲池初始化的时候，会创建一个free链表，每个结点都是一个空白缓冲页的控制块，当从磁盘读取到数据后，便从这个free链表拿到控制块，找到空白缓存页的地址，将磁盘数据拷贝进去

### lru链表

数据拷贝进空白缓存页之后，free链表便移除它的控制块的结点，按照一定顺序放入lru链表

lru即least recent use，最近最少使用，整个链表大体上按照使用时间进行排序，长时间未被使用的会被放到队尾，在链表满了，但又需要从磁盘加载新的页的时候优先淘汰

#### 提高查询速度

当我们要查找的页已经保存在缓冲池的时候，便减少了一个从磁盘拿数据的操作，直接使用缓冲池的数据，从而起到一个缓存加速的作用

#### 热数据(young区)与冷数据(old区)

有这么个问题，当我们使用范围查询加载了大量的页，页的数量甚至超过了缓冲池的容量，那么这时会怎样？缓冲池中那些经常用到的缓存页被这次范围查找给顶没了

即使我们范围查找的页不会完全覆盖缓冲池的所有缓存页，mysql具有预读的功能，即你读取了某些页面，mysql会猜测你会读取后面的页面，从而将页预先加载到缓冲池，那么也有可能把缓冲池完全替换掉

又或者忘记加索引导致的全量查询也会导致这种问题

这很明显会影响到lru链表的实用性，缓存命中率降低

为了阻止缓冲池被完全替换，设计者将lru链表划分为**热数据与冷数据**

* 根据配置将lru链表分成两半，lru前半部分为热数据、后半部分为冷数据，冷数据默认占37%
* 从磁盘加载某个页时，将这个页放到old区的头部(即所有从磁盘加载的页不能进入young区)
* 当该页面已经在lru链表中，被再次访问到时
  * 若页面在old区
    * 距离上次访问页的时间间隔大于1秒 -> 将缓存页放到young区的头部
    * 时间间隔小于1秒 -> 不移动缓存页

      ps: 每次访问一条记录都会被当做访问一次页面，一个查询的间隔很小概率会大于1秒，因此1秒的判断是为了阻止一个范围查询便把缓存页放到young区头
  * 若页面在young区
    * 在young区的前1/4内 -> 不移动
    * 不在young区的前1/4内 -> 移动到young区头

      ps: 处于前1/4这个位置基本不会被淘汰掉，而且是命中概率比较高的页，每次命中都移动到链表头也没有这个必要，为了节约性能便跳过了



### flush链表

数据从磁盘加载到lru链表后，这时我们执行了修改语句对数据进行了修改，lru链表内的缓存页便与磁盘内真实页的产生差异，即脏页，需要把这些脏页更新到磁盘

缓存页每次发生修改便实时地将数据同步到磁盘显然不实际的，性能拉垮

因此需要定时地将多个脏页一起同步到磁盘，但在定时任务中mysql又怎么知道那些缓存页是脏页，遍历整个lru链表感觉可以，但考虑性能的话就不太行了

因此还需要这么一个脏页链表flush，将脏页链接起来，定时任务直接从flush链表拿出脏页，再同步到磁盘



# 脏页同步回磁盘的时机

* 定时任务
  * 从lru链表尾部扫描一些页面，发现脏页则刷新到磁盘
  * 从flush链表刷新部分页面到磁盘

* 产生新的脏页时，lru或flush链表没有空间

  用户请求从磁盘加载新的页，但lru链表没有剩余空间，则会在尾部查找没有修改的页释放掉，没找到则不得不拿一个脏页为目标，刷新到磁盘再释放掉

* 数据库正常关闭

* 存储redolog的空间满了

  存储redolog的空间满了后，需要将脏页



# redo log

脏页依赖后台线程定时刷新到磁盘，无法实时同步，加入这时进程崩溃，那么还没刷新进磁盘的脏页不就丢了么?

* 为了降低进程崩溃带来的影响，需要一种更高频率的同步机制

利用脏页同步到磁盘的话，每改一条记录就要同步一个页的数据，显然有点浪费，高频同步便会消耗更多的性能

* 为了提升高频同步的性能，同步数据需要更小



redo log便是这么一种在进程崩溃时减少数据丢失，相对脏页同步更高频的、数据体积更小的磁盘同步机制



## redo log的结构

- spaceId 表空间id

* pageNum 页号
* type 日志类型
* offset 页内偏移量
* value 修改后的值

根据spaceId、pageNum、offset定位到页内要修改的位置，长度，将值改为value



**type的分类**

* MLOG_1BYTE 在偏移量写入1个字节
* MLOG_8BYTE
* MLOG_WRITE_STRING redo log 会多保存一个len字段，在偏移量写入len个字节,
* ...



## Mini-Transaction

一条sql执行后并不一定只有一条redolog

例:

* 在一个新页插入一条新的记录，除了记录本身外还有各种数据，页头页尾等，可能需要多条redolog

* 一个事务执行多条语句，也会产生多条redolog

  

假设这批redolog同步一半服务崩了，剩下一半没同步会怎样? 磁盘保存的redolog对应的数据便是异常的



因此这批redolog需要作为一个组，以组的形式写入磁盘，要么一起成功，要么一起失败，这样的组称为Mini-Transaction，迷你事务，缩写mtr



**如何识别多个redolog为一个mtr？**

redolog的type有个取值为MLOG_MULTI_REC_END，



## redo log buffer

写入磁盘是一个阻塞且缓慢的过程，即使redo log相对脏页更加高频，也不能实时地写入磁盘，这会影响性能，而是先写到redo log buffer这个内存空间中，然后在合适的时间把redo log buffer的数据同步到磁盘



## redo log更新到磁盘的时机

* 后台线程定时刷新，大概每秒一次
* 事务提交时
* log buffer空间不足
* checkpoint
* 正常关闭服务器

定时任务每秒执行一次更新，每个事务提交后也会更新，频率比脏页的同步搞了很多，进一步确保数据的安全性，即使崩溃，至多也就丢失1秒的数据



脏页跟redolog都会定时更新到磁盘，脏页是直接修改磁盘整个页内容，redolog则是在进程崩溃的时候根据log内容需改指定页、偏移量的值来更新数据，脏页的数据同步结果也是redolog同步结果

那么当进程崩溃时我们要恢复数据的时候，怎么知道哪些redolog直接或通过脏页间接地刷新到磁盘，哪些redolog没刷新



# Log Sequence Number

为了识别那些redolog先执行、哪些后执行，需要这么一个数字标记redolog的先后顺序，即日志序列号，缩写lsn

与自增id类似，但不同的是，并不是每次都+1，而是直接加上日志量的大小。

例如lsn的初始值是8704(为什么是这个数我也不知道)，当某个mtr产生的日志量为200字节(里面不仅仅只有日志，还有存储日志所需的结构)，则lsn就变成8704 + 200 = 8904

因此每一组mtr都有一个lsn与其对应，lsn越小，说明日志产生时间越早，同一组mtr内的redolog共用一个lsn



## flushed_to_disk_lsn

磁盘中也保存了一个lsn，对应最后保存到磁盘上的redolog的lsn，即flushed_to_disk_lsn，内存中的lsn比flushed_to_disk_lsn大时，便说明内存中存在未保存到磁盘的redolog

redolog有没有刷新到磁盘、哪个先刷新的问题通过比较lsn与flushed_to_disk_lsn解决了，那么脏页刷新到磁盘后，怎么知道这个脏页对应了那些redolog记录，在数据恢复的时候直接跳过这些redolog



## flush链表的lsn

为了使脏页能与redolog对应上，脏页的控制块也要保存一个lsn，当这个lsn与redolog的lsn一致时，说明当前脏页的数据与是该redolog执行后的结果



脏页保存了两个lsn，**oldest_modification**对应首次发生修改的操作的lsn，**newest_modification**对应最后一次发生修改的操作的lsn，flush链表是个FIFO链表，先发生修改的脏页放入链表尾部，并先保存到磁盘，因此脏页是按oldest_modification从小到大的顺序同步到磁盘的



磁盘空间是有限的，不能存储所有的redolog，改怎么判断磁盘中的日志是可以丢弃的?



# checkpoint

为了记录可以丢弃的redolog，磁盘记录了另一个lsn - **checkpoint**，磁盘内lsn小于checkpoint的redolog是可以被删除的



**checkpoint是怎么更新的**

checkpoint记录了可以删除的redolog的lsn，而redolog是为了恢复崩溃时没有保存进磁盘的脏页，当脏页刷进磁盘后，显然其对应的redolog已经没有保存的必要了，因此每次将脏页刷新进磁盘后，都会将checkpoint更新为脏页的oldest_modification的值



**为什么使用oldest_modification而不是newest_modification?**

* 脏页是按照oldest_modification从小到达的顺序刷新到磁盘的，newest_modification则不一定
* newest_modification可能大于未刷新到磁盘的脏页的oldest_modification

显然，把newest_modification作为checkpoint将会把未保存到磁盘的脏页的redolog给删掉



**数据已保存到磁盘，但未删除的redolog**

当一个脏页的oldest_modification与newest_modification不一致时，脏页中可能存在部分数据已保存进磁盘，但对应的redolog还保留着，但这些redolog会随着新的脏页的刷入而删除；而且这部分redolog在用于数据恢复时，假设redolog的lsn小于newest_modification，则说明这些redolog对应的数据已经刷新到磁盘了，直接跳过



# WAL

WAL即Wirte-Ahead Logging，预写日志；

相对于脏页保存到磁盘的时机，redolog更新到磁盘的频率更高，会更快的保存到磁盘