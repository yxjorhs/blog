# 数据库的多样化

## 存储位置

### 内存与磁盘

* 材质：IC电路；磁盘

* 速度：内存-经过内存主线，操作IC电路，速度快；磁盘-经过磁盘主线，寻道、寻址，发生电磁转化，速度慢
* 价格：每GB为单位比较的话，磁盘更便宜
* 持久化：内存数据随断电、或进程结束消失，不支持持久化



### 为什么内存不能持久化、而磁盘可以

* 内存使用IC电路来存储数据，依赖电压来存储数据，发生断电时电压消失，即存储的数据消失
* 磁盘是在盘片上涂了一层磁性材料，依赖磁场来存储数据，修改数据其实是产生电磁场来改变材料的磁场，这种磁场并不会因为电源的中断而消失
* 非易失性内存(non-volatile memory, **NVM**)，当电流关掉后，存储数据不会丢失的内存数据；它可以是一种技术，例如各种内存数据库的持久化，或者是一种新型的内存存储材料



### 为什么内存比磁盘快

内存写入：CPU发送电信号、经过内存总线，使内存中的IC电路发生电压变化

磁盘写入：CPU电信号、经过磁盘总线、在磁盘上寻道、寻址，找到目标磁粉，产生电磁转化，修改磁粉磁场

CPU可以将磁盘的数据拷贝到内存，但一般CPU向**DMA**(Direct Memory Access，直接存储器访问)发送指令，让**DMA**获得总线控制权、完成数据拷贝，减少CPU占用



磁盘的材质决定了他的读写速度，但其持久化的特性又不得不把数据存储到磁盘上。我们无法在代码层次解决磁盘慢的缺点，但基于不同的应用场景，可以通过合理的**索引**、**数据存储方式**来减少磁盘的读写频率，减少扫描数据量来节约磁盘带宽的开销，或是减少随机IO带来的寻道、寻址



## 索引

帮助我们快速找到目标的，生活中：书本的页码、酒店的房间号、找地方问路人都可以称得上是索引的一种，在编程中大部分是指特定的数据结构，帮助我们将查找目标的时间复杂度由O(n)降低到O(logn)甚至是O(1)，即避免遍历

### HashTable

* 实现
  * 数组、散列
  * 内存数据库: Map<key, value>，例: redis
  * 磁盘数据库: Map<key, value在磁盘的地址>，例: bitcask
* 优点：读写的时间复杂度都是O(1)
* 缺点：
  * 哈希冲突，且导致搜索的时间复杂度随哈希冲突的处理手段影响
  * 范围查询：当数据保存在磁盘时、范围查询需要多次随机IO、效率不高
  * 哈希表需要内存加载整个索引，数据多时索引可能超过内存大小；理论上可以将索引放入磁盘、但无法预算索引最终大小，索引会存储在多个段上，取出整个哈希表需要执行多次磁盘随机IO，同时占用大量磁盘带宽，性能低



### LSM-Tree

* 设想
  * 为了对大量数据作索引，随着索引体积的增大，将索引放入磁盘是一种必然；假设哈希表可以只取出key对应的那一部分的槽的话，那么便可以避免内存加载整个哈希表的问题
  * 将保存在段中的数据排序，后面的段第一个key必然大于前面的段的最后一个key，内存建立段首个key的索引(稀疏索引)，查找时对稀疏索引二分查找，找出key所在段，从磁盘获取这个段的数据，找出key的值
* 实现
  * 写请求：为了保持排序，key先写入内存的红黑树中(**内存表**)；当内存表大小超过指定阈值时，将内存表数据保存到磁盘的段中，这写有序段便是**SSTable**（sorted string table）；
  * 段合并：后台需要对段进行合并，丢弃冗余的旧数据；由于段都是有序的，合并段便只需要像合并两个有序链表一样，每次取出最小值到一个新的段中；同时维护内存中的已合并段的稀疏索引
  * 读请求:  
    * 从内存表查找，不存在则查找磁盘上的未合并段，依旧不存在则利用稀疏索引查找已合并段(合并段可能具有多种级别、以及对应的稀疏索引);
    * 查找一个不存在的key将会从最新的段查找到最老的段，查找速度很慢，因此写入时需要多维护一个**布隆过滤器**，读取时先用布隆过滤器判断是否存在
  * 崩溃恢复:  崩溃时整个内存表的数据会丢失，因此写时需要维护多一个日志文件，按写请求的顺序来保存到磁盘，用作崩溃恢复，即WAL(write ahead log)
* LSM存储引擎: 合并、压缩排序文件
* LevelDB、RocksDB、Lucene，HBase与Cassandra使用了LevelDB
* 问题
  * 压缩占据大量的磁盘带宽、影响写入性能
  * 写入速度超过压缩速度时会导致磁盘占用持续增长



### B-Tree

* 实现
  * 按key排序(例：聚簇索引的自增id、二级索引的索引字段)
  * 记录、页、页号、页指针形成了以页为节点的树状结构，**页内记录索引槽**实现了以O(logn)的时间复杂度从根节点到达叶节点
  * 分支因子: 每个页存储多少个页的信息; 假设每个页4K，每个页可存储500个页的信息，分支因子500，那么4级树便可容纳256TB的数据
* 读写的时间复杂度都是O(logn)
* 与LSM-Tree比较
  * 读：两边内存缓存都不命中的情况下，B-Tree最差只需要取出几个页(页大小一般为几K，数量取决于B-Tree的深度)的数据即可读到目标记录；LSM-Tree可能需要查找多个段(每个段大小几M，段的数量取决于合并产生的段文件的新老代数)，从随机IO次数，带宽占用而言，B-Tree的性能优于LSM-Tree；
  * 写：当目标页不在缓冲池时，B-Tree需要从磁盘通过随机IO找出记录所在页复制到内存进行修改，性能低于LSM-Tree的直接修改内存表的指定记录，因此LSM-Tree的写入操作能支持更高的吞吐量（不考虑后台线程执行磁盘压缩产生的干扰的话）
  * 文件大小：LSM-Tree可以支持更好的压缩、以及B-Tree的空间碎片问题，LSM-Tree一般比B-Tree小；但同时LSM-Tree的压缩也会消耗磁盘大量性能与带宽，进而影响写入性能




## 列存储



### OLTP与OLAP

* OLTP: online transcation processing，在线事务处理，使用目标多是平常用户，多个用户的数据存储位置不具有连续性，多个查询伴随大量的随机IO，性能上的瓶颈往往是磁盘寻道的开销
* OLAP: online analystic processing ，在线分析处理，使用目标多是数据分析人员，查询频率不高，但会扫描大量的数据，即使合适的优化可以避免过多的随机IO，但不能避免这些扫描数据量，性能上的瓶颈往往是磁盘带宽



### 列存储

* OLTP场景中，大部分请求是为了查询某个记录的多个字段，因此适用适用面向行的存储方式，即一行的所有列在磁盘上连续存储，那么只需要一次随机IO，接下来再顺序IO便能获取这条记录的所有信息；
* 但OLAP场景中，更多的是分析类的查询，往往需要对大量的行中的一个或多个列执行sum、avg、max、min等操作；
* 将设使用面向行的存储方式，在加载这些查询必要数据的过程中，必定会加载其他非必须列的数据，影响查询执行的速度
* 为了加速分析查询，可以数据由行存储转变为面向列存储，即不同行的列在磁盘上连续存储，这样便可避免加载无用的数据列



### 列压缩

假设用列存储保存上亿条数据，我们要对列进行分析操作的时候，例如sum，需要把上亿条数据遍历一遍，合适的压缩方式在起到减少磁盘占用的同时，甚至能提高遍历的时间复杂度



* 位图压缩

  设想

  假设这上亿条数据的指定列的取值为[1,100]，将数据与取值范围转为为一个由0，1组成的二维数组

  | 模值\列值是否等于模值\列值 | 9    | 12   | 66   | 2    | 23   | ...  |
  | -------------------------- | ---- | ---- | ---- | ---- | ---- | ---- |
  | 1                          | 0    | 0    | 0    | 0    | 0    | /    |
  | 2                          | 0    | 0    | 0    | 1    | 0    | /    |
  | 3                          | 0    | 0    | 0    | 0    | 0    | /    |
  | ...                        | /    | /    | /    | /    | /    | /    |

  用二位数组表示这个位图

  ```
  [
  	[0,0,0,0,0...],
  	[0,0,0,1,0...],
  	[0,0,0,0,0...]
  ]
  ```

  以0，1的顺序对位图数组压缩后变为，奇数位代表0，偶数代表1，最终压缩后的数据为

  ```
  [
  	[5...]
  	[3,1,0...],
  	[5]
  ]
  ```

  优点

  * 当数据量足够大，并且伴随连续的0、1出现时，例如[[10000, 10000...]]，那么压缩能起到巨大的优化，磁盘占用从20000B变为2B，遍历的时间复杂度从原来的20000变成压缩后的2
  * CPU的L1缓存通常为几十K到几百K或几M，相同大小的数据段，列压缩使得更多记录加载到L1缓存中

  缺点

  * 数据量小时，值连续性不强时，压缩不会起到效果
  * 压缩会将数据拆分为多个存储段，遍历时也可能会产生更多的随机IO（当数据量小，数据原本只需要占用一个存储段，压缩却会产生多个存储段）

  实施

  * 写请求只保存到压缩前的数据，数据的压缩由后台线程执行
  * 列压缩需要设定一个阈值，超过这个域值才会进行压缩

### 列排序

* 对存在先后顺序的列进行排序可起到加快查询的作用，例如日期，排序后可使用二分法定位，无须遍历列
* 排序后使得相同值连续，提高列压缩的质量
* 多列排序，第一列排序值相同时，可选择更多的列排序
* 列存储使用数据在列文件中的位置来判断属于哪一行，例如每个列存储的第一个值组成第一行的记录，因此单独对某一行进行排序是没有意义的，当对指定的一个或多个列进行排序后，其他列也要这个顺序排序
* 当数据需要复制到多台服务器内时，数据可以采用多种排序方式存储，即可加速不同的查询方式，同时也能起到数据备份的作用



参考书籍: 

* [数据密集型应用系统设计](https://book.douban.com/subject/30329536/)

